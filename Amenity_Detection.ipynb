{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amenity-Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTWsCHJVYSiMd2XRePjQ2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkhanna19/amenity-detection/blob/master/Amenity_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr8yDuUUlYfd",
        "colab_type": "text"
      },
      "source": [
        "# Amenity Detection with Detectron2 üõãüì∫‚òïÔ∏è\n",
        "\n",
        "This notebook documents Group 6's machine learning project for GATECH CS 4641.\n",
        "\n",
        "\n",
        "![kitchen](https://user-images.githubusercontent.com/31427851/88501290-0b9ce900-cf99-11ea-9195-6768db11a29d.png)\n",
        "\n",
        "Sample image taken from [here](https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e).\n",
        "\n",
        "The image above is the result of a customized computer vision model trained by Airbnb engineers. Computer vision is a field of artificial intelligence that trains computers to understand digital images or videos. The generation of these bounding boxes relates to a sub-field of computer vision, object detection, which involves the detection of semantic objects of certain classes.\n",
        "\n",
        "### First off, what is an amenity?\n",
        "An amenity is a useful feature of a building or place. A couch, a dining table, or a refrigerator \n",
        "\n",
        "### Why would we want to detect amenities?\n",
        "\n",
        "When Airbnb lists a home or apartment or Trivago lists a hotel room, the service must label the amenities on their listings to match the actual furnishings of the property. Human efforts in this regard are not only fallible but also not sustainable. Computer vision models can automatically identify amenities from listing photos, eliminating the time and friction involved with generating a listing. Moreover, tagging photos and listings based on specific amenities grants users further granularity when searching for listings.\n",
        "\n",
        "Suppose a user needsa walk-in shower because they have a wheelchair. The host may not think it's important to list this amenity, but a computer vision algorithm could pick up on it from the photos and allow the user to find listings that match their needs.\n",
        "\n",
        "Now, let's take a look at the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFCxC0j1YK9M",
        "colab_type": "text"
      },
      "source": [
        "### Open Images Dataset\n",
        "\n",
        "The [Open Images Dataset](https://storage.googleapis.com/openimages/web/index.html) is a massive machine learning dataset generated by Google. This dataset contains relationship narratives, annotations, and localized narratives for over 3 million images. \n",
        "\n",
        "The below histogram documents how many images there exist for each class in Open Images.\n",
        "\n",
        "![data](https://user-images.githubusercontent.com/31427851/88501309-16577e00-cf99-11ea-97f3-b0a7cbbdf86c.png)\n",
        "\n",
        "Open Images also offers 15,851,536 boxes on 600 categories. Because we are interested in an Object Detection use case, this property is most relevant to us. To make the most of our computing resources and time constrains, we will build a customized model to focus on two classes: fireplace and coffeemaker.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6hEJzbVOuS4",
        "colab_type": "text"
      },
      "source": [
        "## Related Work\n",
        "\n",
        "This work is inspired in large part by the work of Airbnb engineers to build an amenity detection model, as documented in [this Medium article](https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e).\n",
        "\n",
        "Airbnb engineers developed a taxonomy of 30 image classes, selecting them from the 600 present in the Open Images dataset, and fused this data with their internal network data. They built models on Google's AutoML and chose two pre-trained models for fine-tuning ssd_mobilenet_v2 and faster_rcnn_inception_resnet_v2. They improved upon the accuracy of generic third-party models substantially, as evinced by the per-class graph of mean average precision (mAP) below.\n",
        "\n",
        "![map-airbnb](https://user-images.githubusercontent.com/31427851/88501295-0dff4300-cf99-11ea-95e2-a26babf89b35.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kxidL3JK5uo",
        "colab_type": "text"
      },
      "source": [
        "## Machine Specifications\n",
        "\n",
        "Let's take a look at what kind of a machine Google Colab has given us.\n",
        "\n",
        "Using the [Tensorflow API](https://www.tensorflow.org/lite/examples), we can reveal the device name, type, and memory limit. We should also determine how much RAM is available to help someone else recreate our findings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xlH8SsUK5DU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac80eee5-5822-4c33-b94f-1e36818ef6a3"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufAoAKb0L6oA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "70ef30ac-06f7-4f6a-8b88-e952007ac51a"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 17137567336604863346, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 14151441755751622264\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 2981426434565437507\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15701463552\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 9901328481589976786\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGvSCZcpMyBs",
        "colab_type": "text"
      },
      "source": [
        "XLA stands for Accelerated Linear Algebra. It's a compiler for linear algebra that can accelerate Tensorflow models. \n",
        "\n",
        "According to the Tensorflow website, the results are improvements in speed and memory usage: \"most internal benchmarks run ~1.15x faster after XLA is enabled.\"\n",
        "\n",
        "Notice how there are two devices in the device list: an XLA CPU and an XLA GPU. GPUs can process data orders of magnitude faster than CPUs because of parallelism and multithreading architectures. Given how much image data we will need to process for this machine learning application, we will rely on its computational power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDYKmOowNwVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "4580094c-a72a-403c-a426-deb213239cc7"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       13333556 kB\n",
            "MemFree:         9246592 kB\n",
            "MemAvailable:   11889900 kB\n",
            "Buffers:           75632 kB\n",
            "Cached:          2680064 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1187980 kB\n",
            "Inactive:        2484612 kB\n",
            "Active(anon):     844276 kB\n",
            "Inactive(anon):     8528 kB\n",
            "Active(file):     343704 kB\n",
            "Inactive(file):  2476084 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               284 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        916996 kB\n",
            "Mapped:           663900 kB\n",
            "Shmem:              9156 kB\n",
            "Slab:             175616 kB\n",
            "SReclaimable:     128824 kB\n",
            "SUnreclaim:        46792 kB\n",
            "KernelStack:        3696 kB\n",
            "PageTables:         8636 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6666776 kB\n",
            "Committed_AS:    3123580 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:           0 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:              920 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      197820 kB\n",
            "DirectMap2M:     7141376 kB\n",
            "DirectMap1G:     8388608 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X45koH4yOBSN",
        "colab_type": "text"
      },
      "source": [
        "It looks like there are ~11.9 GB in available memory on this GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TYTWwRU39GT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b5f0d6ec-7ad6-4ecc-820d-cde85ddae6f4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 27 15:24:22 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M04d58g74EXJ",
        "colab_type": "text"
      },
      "source": [
        "We are running an NVIDIA Tesla K80 GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FJ3POocONpl",
        "colab_type": "text"
      },
      "source": [
        "## Getting into the Weeds\n",
        "\n",
        "Detectron2, the pre-built computer vision model we will train on our amenity-specific data, relies on [Facebook's PyTorch Library](https://pytorch.org/).\n",
        "\n",
        "FIrst, let's install the python-specific PyTorch dependencies. Next, we will install a few other packages we need for our data wrangling, and we will import all of the common python libraries used for machine learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0qeSgLLK1CY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9a56d068-58b3-412e-beee-9504c3ea7eb5"
      },
      "source": [
        "# Python's torch library supports tensor computation with GPU acceleration\n",
        "# Detectron2 is built with PyTorch\n",
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Let's make sure that worked\n",
        "import torch, torchvision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.4+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (723.9MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723.9MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (4.0MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.1MB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.4.0+cu100 torchvision-0.5.0+cu100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGGzne8U_h0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pyaml will allow us to parse yaml files which contain information about machine learning\n",
        "!pip install cython pyyaml==5.1\n",
        "\n",
        "# COCO (Common Objects in COntext) is a large scale object detection, segmentation, and captioning dataset\n",
        "# Detectron2 is trained on the COCO dataset\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "!pip install awscli # let's us download images from Open Images using downloadOI.py script"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNAu4RZjMmRh",
        "colab_type": "text"
      },
      "source": [
        "Now let's install the Detectron2 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqQdnPEDE6oU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "c1d8f9e6-4efd-4b4e-ede5-598a7dedd871"
      },
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.6/dist-packages (0.2+cu100)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Processing /root/.cache/pip/wheels/86/19/08/49b25f258ead1f861c9ab2fc41f73636f2928859adbb0e9797/pycocotools-2.0.1-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: fvcore>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.1.post20200716)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: Pillow>=7.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.0.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.7)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->detectron2) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->detectron2) (49.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2) (5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2) (1.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.30.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.34.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (1.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.1.0)\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed pycocotools-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRv8Emf4MtY-",
        "colab_type": "text"
      },
      "source": [
        "We'll import some common libraries first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_7KAAWgMtM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm # we'll need this for downloading the data\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3XUt27dM12j",
        "colab_type": "text"
      },
      "source": [
        "Now let's make sure we have Detectron2 set up on our machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhOGyXli5k3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import detectron2\n",
        "\n",
        "# setup_logger contains a formatter that will allow us to see\n",
        "# what's going on with the mmodel during training and will help us\n",
        "# debug if any issues arise\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWrq_ooqNYqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2 import model_zoo # a series of pre-trained Detectron2 models: https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md\n",
        "from detectron2.engine import DefaultPredictor # a default predictor class to make predictions on an image using a trained model\n",
        "from detectron2.config import get_cfg # a config of \"cfg\" in Detectron2 is a series of instructions for building a model\n",
        "from detectron2.utils.visualizer import Visualizer # a class to help visualize Detectron2 predictions on an image\n",
        "from detectron2.data import MetadataCatalog # stores information about the model such as what the training/test data is, what the class names are"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcbzb7efNc9i",
        "colab_type": "text"
      },
      "source": [
        "## Run a Pre-Trained Model\n",
        "Let's start having some fun! We will download the image from the Airbnb Article Cover visualize it using OpenCV.\n",
        "\n",
        "Since the Open Images dataset are public, a big dog model was trained on as many of the public images as possible.\n",
        "\n",
        "Airbnb selected 30 target classes that were relevant to amenity detection from Open Images and trained a model to identify the images.\n",
        "\n",
        "\n",
        "Let's download the full trained model and make a prediction on the article cover."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiX_D1iA5spV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cdd6566e-52c1-485a-ff29-893229a59647"
      },
      "source": [
        "# Download and display example image and save it as demo.jpeg\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/airbnb-amenity-detection/master/custom_images/airbnb-article-cover.jpeg -O demo.jpeg\n",
        "img = cv2.imread(\"./demo.jpeg\")\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85dKvxWnG5Pd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "bc2633f1-0d53-4956-eab8-38279b825687"
      },
      "source": [
        "# Download the trained model\n",
        "!wget https://storage.googleapis.com/airbnb-amenity-detection-storage/airbnb-amenity-detection/open-images-data/retinanet_model_final/retinanet_model_final.pth \n",
        "\n",
        "# Download the train model config (instructions on how the model was built)\n",
        "!wget https://storage.googleapis.com/airbnb-amenity-detection-storage/airbnb-amenity-detection/open-images-data/retinanet_model_final/retinanet_model_final_config.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-26 15:08:02--  https://storage.googleapis.com/airbnb-amenity-detection-storage/airbnb-amenity-detection/open-images-data/retinanet_model_final/retinanet_model_final.pth\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 108.177.121.128, 74.125.124.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 446656531 (426M) [application/octet-stream]\n",
            "Saving to: ‚Äòretinanet_model_final.pth.1‚Äô\n",
            "\n",
            "retinanet_model_fin 100%[===================>] 425.96M  8.67MB/s    in 60s     \n",
            "\n",
            "2020-07-26 15:09:02 (7.12 MB/s) - ‚Äòretinanet_model_final.pth.1‚Äô saved [446656531/446656531]\n",
            "\n",
            "--2020-07-26 15:09:02--  https://storage.googleapis.com/airbnb-amenity-detection-storage/airbnb-amenity-detection/open-images-data/retinanet_model_final/retinanet_model_final_config.yaml\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 172.217.214.128, 108.177.111.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5534 (5.4K) [application/octet-stream]\n",
            "Saving to: ‚Äòretinanet_model_final_config.yaml.1‚Äô\n",
            "\n",
            "retinanet_model_fin 100%[===================>]   5.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-26 15:09:02 (69.1 MB/s) - ‚Äòretinanet_model_final_config.yaml.1‚Äô saved [5534/5534]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Tl9U9kO0Qp",
        "colab_type": "text"
      },
      "source": [
        "### Airbnb's 30 Target Classes\n",
        "\n",
        "We'll feed the classifier a list of Airbnb's 30 target classes to identify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TDHkoCXHkwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Airbnb's target classes\n",
        "target_classes = ['Bathtub',\n",
        " 'Bed',\n",
        " 'Billiard table',\n",
        " 'Ceiling fan',\n",
        " 'Coffeemaker',\n",
        " 'Couch',\n",
        " 'Countertop',\n",
        " 'Dishwasher',\n",
        " 'Fireplace',\n",
        " 'Fountain',\n",
        " 'Gas stove',\n",
        " 'Jacuzzi',\n",
        " 'Kitchen & dining room table',\n",
        " 'Microwave oven',\n",
        " 'Mirror',\n",
        " 'Oven',\n",
        " 'Pillow',\n",
        " 'Porch',\n",
        " 'Refrigerator',\n",
        " 'Shower',\n",
        " 'Sink',\n",
        " 'Sofa bed',\n",
        " 'Stairs',\n",
        " 'Swimming pool',\n",
        " 'Television',\n",
        " 'Toilet',\n",
        " 'Towel',\n",
        " 'Tree house',\n",
        " 'Washing machine',\n",
        " 'Wine rack']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOkVNZyISn51",
        "colab_type": "text"
      },
      "source": [
        "Let's make a prediction and visualize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuOZ3lgtH32-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup a model config file (set of instructions for the model)\n",
        "cfg = get_cfg() # setup a default config, see: https://detectron2.readthedocs.io/modules/config.html\n",
        "cfg.merge_from_file(\"./retinanet_model_final_config.yaml\") # merge the config YAML file (a set of instructions on how to build a model)\n",
        "cfg.MODEL.WEIGHTS = \"./retinanet_model_final.pth\" # setup the model weights from the fully trained model\n",
        "\n",
        "# Create a default Detectron2 predictor for making inference\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Make a prediction the example image from above\n",
        "outputs = predictor(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ThGrxlINdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of predicted amenities to draw on the target image\n",
        "num_amenities = 7\n",
        "\n",
        "# Set up a visualizer instance: https://detectron2.readthedocs.io/modules/utils.html#detectron2.utils.visualizer.Visualizer\n",
        "visualizer = Visualizer(img_rgb=img[:, :, ::-1], # we have to reverse the color order otherwise we'll get blue images (BGR -> RGB)\n",
        "                        metadata=MetadataCatalog.get(cfg.DATASETS.TEST[0]).set(thing_classes=amenity_list), # we tell the visualizer what classes we're drawing (from the target classes)\n",
        "                        scale=0.7)\n",
        "\n",
        "# Draw the models predictions on the target image\n",
        "visualizer = visualizer.draw_instance_predictions(outputs[\"instances\"][:num_amenities].to(\"cpu\"))\n",
        "\n",
        "# Display the image\n",
        "cv2_imshow(visualizer.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlbWqoMQThln",
        "colab_type": "text"
      },
      "source": [
        "### Download the Image Labels\n",
        "\n",
        "This process will allow us to preprocess the data. The Image Labels have all of the information about the bounding boxes for the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3cZyO42I4s6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training bounding boxes (1.11G)\n",
        "!wget https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv\n",
        "\n",
        "# Validating bounding boxes (23.94M)\n",
        "!wget https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv\n",
        "    \n",
        "# Testing bounding boxes (73.89M)\n",
        "!wget https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv\n",
        "\n",
        "# Class names of images (11.73K)\n",
        "!wget https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eI0QAPdS3y1",
        "colab_type": "text"
      },
      "source": [
        "## Training our Customized Detectron2 Model\n",
        "\n",
        "First, we'll download the training data from a Google Storage bucket to save download time. Next we'll visualize the training data to ensure it matches up with our expectations. After, we will preprocess the data -- combine the images and the labels so that Detectron2 knows where the bounding boxes are. Finally, we'll use [DefaultTrainer](https://detectron2.readthedocs.io/modules/engine.html?highlight=defaulttrainer#detectron2.engine.defaults.DefaultTrainer) to start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTU191aePXaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get coffeemaker and fireplace training images from Open Images and unzip them\n",
        "!wget https://storage.googleapis.com/airbnb-amenity-detection-storage/airbnb-amenity-detection/open-images-data/cmaker-fireplace-train.zip\n",
        "!unzip -q cmaker-fireplace-train\n",
        "\n",
        "# Get coffeemaker and fireplace validation images from Open Images and unzip them\n",
        "!wget https://storage.googleapis.com/airbnb-amenity-detection-storage/airbnb-amenity-detection/open-images-data/cmaker-fireplace-valid.zip\n",
        "!unzip -q cmaker-fireplace-valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD_e_gYFTDms",
        "colab_type": "text"
      },
      "source": [
        "We'll store the training and testing paths, so that we can point the classifier towards them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHQzLhiOPl6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = \"./cmaker-fireplace-train/\"\n",
        "valid_path = \"./cmaker-fireplace-valid/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM-qU7VITKyN",
        "colab_type": "text"
      },
      "source": [
        "We'll sample an image from the training set to make sure nothing has gone amiss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2yRc4_-PsEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# Read in a random image from the training directory\n",
        "train_img = cv2.imread(train_path + random.sample(os.listdir(\"./cmaker-fireplace-train\"), 1)[0])\n",
        "cv2_imshow(train_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}